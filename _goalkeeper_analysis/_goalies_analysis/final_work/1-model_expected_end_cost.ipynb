{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression to see the relationship between the features and the player's \"end_cost\"\n",
    "\"end_cost\" is the cost of a player at the end of each fantasy season. We can use it to see how the fanstay algo values a player's impact over the course of the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 33)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import goalie-specific, model ready csv\n",
    "\n",
    "goalie_hist_model_ready = pd.read_csv(\"C:/Users/Daniel Quinn/Desktop/Bootcamp/Project_2/data/processed/goalie_hist_model_ready.csv\")\n",
    "#Ensure we can read the whole dataframe, without \"...\"\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "goalie_hist_model_ready = goalie_hist_model_ready.drop(columns = ['Unnamed: 0'])\n",
    "goalie_hist_model_ready.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 34)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create saves percentage stat - will use NaN's to drop irrelevant goalies\n",
    "\n",
    "#Create Saves Percentage stat:\n",
    "\n",
    "goalie_hist_model_ready[\"Saves_Percentage\"] = (\n",
    "    (goalie_hist_model_ready['saves'] + goalie_hist_model_ready['penalties_saved']) /\n",
    "    (goalie_hist_model_ready['saves'] + goalie_hist_model_ready['penalties_saved'] + goalie_hist_model_ready['goals_conceded'])\n",
    ") * 100\n",
    "goalie_hist_model_1_ready = goalie_hist_model_ready.dropna()\n",
    "goalie_hist_model_1_ready.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-Value test on statsmodel regression\n",
    "\n",
    "I ran a number of different models here. Starting on with a maximal features list, I used each inteatio to pare back the stat. insignificant.\n",
    "\n",
    "Foir example, \"start_cost\" overwhelmed the model initially, so I removed it and kept doing so until I got a model that returned p values that made sense.\n",
    "\n",
    "What \"made sense?\" Intuitively, it made no sense for a \"start_cost\" to essentially ignore saves and clean sheets when assessing the value of a goalie at the end of the season.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minutes                       0.952519\n",
       "expected_goal_involvements    0.784980\n",
       "ict_index                     0.726721\n",
       "bps                           0.713543\n",
       "starts                        0.637350\n",
       "expected_goals_conceded       0.519998\n",
       "goals_conceded                0.474923\n",
       "penalties_saved               0.470761\n",
       "clean_sheets                  0.431686\n",
       "saves                         0.352007\n",
       "own_goals                     0.321933\n",
       "bonus                         0.282440\n",
       "assists                       0.281112\n",
       "total_points                  0.219594\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the p-value to determine the statistical significance of each features\n",
    "\n",
    "goalie_hist_model_2_ready = goalie_hist_model_1_ready[['minutes', 'total_points', 'clean_sheets', 'goals_conceded',\n",
    "                                                       'saves', 'ict_index', 'bonus', 'bps',\n",
    "                                                       'expected_goals_conceded', 'starts', 'penalties_saved', 'expected_goal_involvements',\n",
    "                                                       'assists', 'own_goals', 'end_cost']]\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#create X & y variables\n",
    "X = goalie_hist_model_2_ready.drop(columns = ['end_cost'])\n",
    "y = goalie_hist_model_2_ready['end_cost']\n",
    "\n",
    "#test-training split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Use the statsmodels package to create and fit a linear regression\n",
    "lr = sm.OLS(y_train, X_train).fit()\n",
    "lr.pvalues.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model score:  0.7208526117402403\n",
      "Test model score:  0.6588366831630601\n"
     ]
    }
   ],
   "source": [
    "#create X & y variables\n",
    "X = goalie_hist_model_2_ready.drop(columns = ['end_cost'])\n",
    "y = goalie_hist_model_2_ready['end_cost']\n",
    "\n",
    "#test-training split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#create model\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train model score: \", model.score(X_train, y_train))\n",
    "print(\"Test model score: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features (end_cost = y):\n",
      "mean squared error (MSE): 9.911793981979073\n",
      "R-squared (R2): 0.6588366831630601\n"
     ]
    }
   ],
   "source": [
    "#Make predictions\n",
    "\n",
    "prediction1 = model.predict(X_test)\n",
    "\n",
    "#Evaluate models with mse and r2\n",
    "\n",
    "mse = mean_squared_error(y_test, prediction1) # how close are the predicted values to actual values via the squared differences between expected and real\n",
    "r2 = r2_score(y_test, prediction1) # r2 - how well do the indep variables explain the variation in the dep var? ) 0 is a perfect model, the larger the nuber, the worse the model is performing\n",
    "\n",
    "print(f\"All Features (end_cost = y):\")\n",
    "print(f\"mean squared error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Model for new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.655486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.521576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.788648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.411417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.863684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>40.960683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>42.660748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>53.417522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>49.318396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>47.365037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    48.655486\n",
       "1    49.521576\n",
       "2    53.788648\n",
       "3    46.411417\n",
       "4    44.863684\n",
       "..         ...\n",
       "176  40.960683\n",
       "177  42.660748\n",
       "178  53.417522\n",
       "179  49.318396\n",
       "180  47.365037\n",
       "\n",
       "[181 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the model to get the predicted end costs for each goalie\n",
    "\n",
    "predicted_end_cost = goalie_hist_model_2_ready.drop(columns = ['end_cost'])\n",
    "y_new_pred = model.predict(predicted_end_cost)\n",
    "y_new_pred\n",
    "exp_end_cost_1 = pd.DataFrame(y_new_pred)\n",
    "exp_end_cost_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9490096019629226\n",
      "Testing Score: 0.6905235082308542\n"
     ]
    }
   ],
   "source": [
    "#create X & y variables\n",
    "X = goalie_hist_model_2_ready.drop(columns=['end_cost'])\n",
    "y = goalie_hist_model_2_ready['end_cost']\n",
    "\n",
    "#test-training split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#create & train model\n",
    "random_forest = RandomForestRegressor(n_estimators=500, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Training Score: {random_forest.score(X_train, y_train)}\")\n",
    "print(f\"Testing Score: {random_forest.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>40.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>40.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>51.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>50.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>48.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0    45.376\n",
       "1    49.154\n",
       "2    54.892\n",
       "3    44.196\n",
       "4    46.408\n",
       "..      ...\n",
       "176  40.284\n",
       "177  40.190\n",
       "178  51.408\n",
       "179  50.256\n",
       "180  48.082\n",
       "\n",
       "[181 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_end_cost_1 = goalie_hist_model_2_ready.drop(columns = ['end_cost'])\n",
    "y_new_pred_1 = random_forest.predict(predicted_end_cost_1)\n",
    "y_new_pred_1\n",
    "exp_end_cost_2 = pd.DataFrame(y_new_pred_1)\n",
    "exp_end_cost_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   0\n",
      "total_points                0.285248\n",
      "clean_sheets                0.247887\n",
      "minutes                     0.143369\n",
      "saves                       0.094906\n",
      "goals_conceded              0.084884\n",
      "bps                         0.039040\n",
      "bonus                       0.031459\n",
      "ict_index                   0.023360\n",
      "expected_goals_conceded     0.015568\n",
      "starts                      0.012127\n",
      "assists                     0.006981\n",
      "expected_goal_involvements  0.006688\n",
      "penalties_saved             0.006231\n",
      "own_goals                   0.002252\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "feature_importances_df = pd.DataFrame(feature_importances, X.columns)\n",
    "\n",
    "\n",
    "print(feature_importances_df.sort_values(by=0, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running models on a different combination of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are using an edited features list - everything here is goalie-centric\n",
    "#  & not necessarily applicable to other positions - what we used for the p-value test above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['minutes', 'total_points', 'clean_sheets', 'goals_conceded', 'saves',\n",
       "       'ict_index', 'bonus', 'bps', 'expected_goals_conceded', 'starts',\n",
       "       'penalties_saved', 'expected_goal_involvements', 'assists', 'own_goals',\n",
       "       'end_cost'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New feature set\n",
    "\n",
    "edit2_goalies_list = goalie_hist_model_2_ready\n",
    "# [['expected_assists', 'starts', 'ict_index',\n",
    "#                                               'red_cards', 'expected_goals_conceded', 'expected_goals',\n",
    "#                                               'bps', 'expected_goal_involvements', 'yellow_cards',\n",
    "#                                               'minutes', 'own_goals', 'goals_scored', 'clean_sheets', 'assists',\n",
    "#                                               'penalties_saved', 'bonus', 'total_points', 'saves', 'goals_conceded', 'end_cost']]\n",
    "\n",
    "edit2_goalies_list.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pvalues below are about the same as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minutes                       0.952519\n",
       "expected_goal_involvements    0.784980\n",
       "ict_index                     0.726721\n",
       "bps                           0.713543\n",
       "starts                        0.637350\n",
       "expected_goals_conceded       0.519998\n",
       "goals_conceded                0.474923\n",
       "penalties_saved               0.470761\n",
       "clean_sheets                  0.431686\n",
       "saves                         0.352007\n",
       "own_goals                     0.321933\n",
       "bonus                         0.282440\n",
       "assists                       0.281112\n",
       "total_points                  0.219594\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the p-value to determine the statistical significance of each features\n",
    "\n",
    "goalie_hist_model_3_ready = edit2_goalies_list[['minutes', 'total_points', 'clean_sheets', 'goals_conceded',\n",
    "                                                       'saves', 'ict_index', 'bonus', 'bps',\n",
    "                                                       'expected_goals_conceded', 'starts', 'penalties_saved', 'expected_goal_involvements',\n",
    "                                                       'assists', 'own_goals', 'end_cost']]\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#create X & y variables\n",
    "X = goalie_hist_model_3_ready.drop(columns = ['end_cost'])\n",
    "y = goalie_hist_model_3_ready['end_cost']\n",
    "\n",
    "#test-training split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Use the statsmodels package to create and fit a linear regression\n",
    "lr = sm.OLS(y_train, X_train).fit()\n",
    "lr.pvalues.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model score:  0.7208526117402403\n",
      "Test model score:  0.6588366831630601\n"
     ]
    }
   ],
   "source": [
    "#create X & y variables\n",
    "X = edit2_goalies_list.drop(columns=['end_cost'])\n",
    "y = edit2_goalies_list['end_cost']\n",
    "\n",
    "#test-training split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#create model\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train model score: \", model.score(X_train, y_train))\n",
    "print(\"Test model score: \", model.score(X_test, y_test))\n",
    "\n",
    "#These are slightly lower than above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features (end_cost=y):\n",
      "mean squared error (MSE): 9.911793981979073\n",
      "Test R-squared (R2): 0.6588366831630601\n"
     ]
    }
   ],
   "source": [
    "#Make predictions\n",
    "\n",
    "prediction1 = model.predict(X_test)\n",
    "\n",
    "#Evaluate models with mse and r2\n",
    "\n",
    "mse = mean_squared_error(y_test, prediction1)\n",
    "r2 = r2_score(y_test, prediction1)\n",
    "\n",
    "#Evaluate & print the model scores\n",
    "print(f\"All Features (end_cost=y):\")\n",
    "print(f\"mean squared error (MSE): {mse}\")\n",
    "print(f\"Test R-squared (R2): {r2}\")\n",
    "\n",
    "# without start_cost, the MSE is 10.75; r2 = 0.63\n",
    "\n",
    "#Full-feature: MSE 1.986 R2 .944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9490096019629226\n",
      "Testing Score: 0.6905235082308542\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "#create X & y variables\n",
    "X = edit2_goalies_list.drop(columns=['end_cost'])\n",
    "y = edit2_goalies_list['end_cost']\n",
    "\n",
    "#test-training split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#create & train model\n",
    "random_forest_2 = RandomForestRegressor(n_estimators=500, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Training Score: {random_forest.score(X_train, y_train)}\")\n",
    "print(f\"Testing Score: {random_forest.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   0\n",
      "total_points                0.285248\n",
      "clean_sheets                0.247887\n",
      "minutes                     0.143369\n",
      "saves                       0.094906\n",
      "goals_conceded              0.084884\n",
      "bps                         0.039040\n",
      "bonus                       0.031459\n",
      "ict_index                   0.023360\n",
      "expected_goals_conceded     0.015568\n",
      "starts                      0.012127\n",
      "assists                     0.006981\n",
      "expected_goal_involvements  0.006688\n",
      "penalties_saved             0.006231\n",
      "own_goals                   0.002252\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "feature_importances_df = pd.DataFrame(feature_importances, X.columns)\n",
    "\n",
    "\n",
    "print(feature_importances_df.sort_values(by=0, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#The total_points metric is a fantasy-generated metric that includes minutes, clean_sheets, saves,\n",
    "# penalties_saved, own_goals, goals_conceded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New dataset predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45.376 49.154 54.892 44.196 46.408 43.992 39.856 44.116 52.146 49.326\n",
      " 50.384 50.784 43.114 40.572 39.85  39.25  41.87  41.674 40.984 39.246\n",
      " 53.72  51.046 44.906 44.518 49.    47.252 39.584 42.116 41.134 44.728\n",
      " 43.506 44.266 46.636 46.594 44.178 44.152 52.082 49.276 44.738 44.424\n",
      " 40.062 41.812 41.18  39.418 42.994 50.222 50.03  50.472 48.226 47.576\n",
      " 45.524 50.334 41.38  41.27  45.772 44.98  50.824 52.486 48.082 45.934\n",
      " 39.94  46.002 43.256 40.942 38.554 46.2   46.428 51.676 43.512 48.554\n",
      " 48.616 43.172 39.558 39.956 40.006 40.34  58.798 58.106 54.602 60.18\n",
      " 52.942 53.048 43.392 42.432 39.334 38.222 48.602 51.59  44.886 41.834\n",
      " 39.36  57.164 58.232 56.882 59.602 60.316 54.01  54.652 38.646 37.614\n",
      " 50.336 50.638 45.21  46.622 43.924 49.242 45.65  49.896 50.426 45.336\n",
      " 44.908 40.872 43.088 40.512 50.952 51.586 53.506 49.382 51.766 49.888\n",
      " 44.396 44.624 50.568 42.09  39.938 39.872 39.668 43.18  45.02  45.896\n",
      " 50.904 49.54  40.478 44.572 41.182 39.988 40.642 44.222 43.158 45.68\n",
      " 44.988 43.758 41.146 55.504 47.648 53.712 45.86  41.332 43.554 43.944\n",
      " 41.056 50.906 46.262 41.23  42.138 43.524 44.918 45.162 46.95  46.046\n",
      " 43.196 41.098 52.37  47.194 47.608 47.918 47.754 47.086 49.84  49.516\n",
      " 48.54  41.128 42.876 47.054 42.402 43.476 40.284 40.19  51.408 50.256\n",
      " 48.082]\n"
     ]
    }
   ],
   "source": [
    "#Run the model to get the predicted end costs for each goalie\n",
    "\n",
    "predicted_end_cost = edit2_goalies_list.drop(columns = ['end_cost'])\n",
    "y_new_pred2 = random_forest_2.predict(predicted_end_cost)\n",
    "print(y_new_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data & create dataframe to hold y_new_pred2 prediction\n",
    "\n",
    "y_new_pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Quinn\\AppData\\Local\\Temp\\ipykernel_37660\\2542174765.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  end_cost_predictions_df_master['Predicted_End_Cost'] = y_new_pred2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(181, 35)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe with expected end_costs\n",
    "\n",
    "end_cost_predictions_df_master = goalie_hist_model_1_ready\n",
    "end_cost_predictions_df_master['Predicted_End_Cost'] = y_new_pred2\n",
    "end_cost_predictions_df_master = end_cost_predictions_df_master[['id', 'first_name', 'second_name', 'team', 'element_type', 'code',\n",
    "       'element_code', 'season', 'total_points',\n",
    "       'minutes', 'goals_scored', 'assists', 'clean_sheets', 'goals_conceded',\n",
    "       'own_goals', 'penalties_saved', 'penalties_missed', 'yellow_cards',\n",
    "       'red_cards', 'saves', 'bonus', 'bps', 'influence', 'creativity',\n",
    "       'threat', 'ict_index', 'starts', 'expected_goals', 'expected_assists',\n",
    "       'expected_goal_involvements', 'expected_goals_conceded',\n",
    "       'Saves_Percentage', 'start_cost', 'end_cost', 'Predicted_End_Cost']]\n",
    "\n",
    "end_cost_predictions_df_master\n",
    "end_cost_predictions_df_master.to_csv(\"C:/Users/Daniel Quinn/Desktop/Bootcamp/Project_2/data/processed/end_cost_predictions_df_master.csv\")\n",
    "end_cost_predictions_df_master.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
